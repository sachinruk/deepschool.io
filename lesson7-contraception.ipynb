{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Merge, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>H_education</th>\n",
       "      <th>num_child</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Employ</th>\n",
       "      <th>H_occupation</th>\n",
       "      <th>living_standard</th>\n",
       "      <th>Media_exposure</th>\n",
       "      <th>contraceptive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Education  H_education  num_child  Religion  Employ  H_occupation  \\\n",
       "0   24          2            3          3         1       1             2   \n",
       "1   45          1            3         10         1       1             3   \n",
       "2   43          2            3          7         1       1             3   \n",
       "3   42          3            2          9         1       1             3   \n",
       "4   36          3            3          8         1       1             3   \n",
       "\n",
       "   living_standard  Media_exposure  contraceptive  \n",
       "0                3               0              1  \n",
       "1                4               0              1  \n",
       "2                4               0              1  \n",
       "3                3               0              1  \n",
       "4                2               0              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cmc.data',header=None,names=['Age','Education','H_education',\n",
    "                                                     'num_child','Religion', 'Employ',\n",
    "                                                     'H_occupation','living_standard',\n",
    "                                                     'Media_exposure','contraceptive'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                False\n",
       "Education          False\n",
       "H_education        False\n",
       "num_child          False\n",
       "Religion           False\n",
       "Employ             False\n",
       "H_occupation       False\n",
       "living_standard    False\n",
       "Media_exposure     False\n",
       "contraceptive      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1473, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5b7857d310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+3+EVQZuGDGgHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b78567d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.contraceptive.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                int64\n",
       "Education          int64\n",
       "H_education        int64\n",
       "num_child          int64\n",
       "Religion           int64\n",
       "Employ             int64\n",
       "H_occupation       int64\n",
       "living_standard    int64\n",
       "Media_exposure     int64\n",
       "contraceptive      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(idx):\n",
    "    y = np.zeros((len(idx),max(idx)+1))\n",
    "    y[np.arange(len(idx)), idx] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[['Age','num_child','Employ','Media_exposure']].values\n",
    "y = one_hot_encoding(df.contraceptive.values-1)\n",
    "\n",
    "liv_cats = df.living_standard.max()\n",
    "edu_cats = df.Education.max()\n",
    "\n",
    "liv = df.living_standard.values - 1\n",
    "liv_one_hot = one_hot_encoding(liv)\n",
    "edu = df.Education.values - 1\n",
    "edu_one_hot = one_hot_encoding(edu)\n",
    "\n",
    "train_x, test_x, train_liv, \\\n",
    "test_liv, train_edu, test_edu, train_y, test_y = train_test_split(x,liv_one_hot,edu_one_hot,y,test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.hstack([train_x, train_edu, train_liv])\n",
    "test_x = np.hstack([test_x, test_edu, test_liv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0s - loss: 1.8914 - acc: 0.4045\n",
      "Epoch 2/100\n",
      "0s - loss: 1.0642 - acc: 0.4317\n",
      "Epoch 3/100\n",
      "0s - loss: 1.0623 - acc: 0.4294\n",
      "Epoch 4/100\n",
      "0s - loss: 1.0602 - acc: 0.4264\n",
      "Epoch 5/100\n",
      "0s - loss: 1.0582 - acc: 0.4287\n",
      "Epoch 6/100\n",
      "0s - loss: 1.0554 - acc: 0.4302\n",
      "Epoch 7/100\n",
      "0s - loss: 1.0555 - acc: 0.4340\n",
      "Epoch 8/100\n",
      "0s - loss: 1.0544 - acc: 0.4370\n",
      "Epoch 9/100\n",
      "0s - loss: 1.0542 - acc: 0.4219\n",
      "Epoch 10/100\n",
      "0s - loss: 1.0535 - acc: 0.4325\n",
      "Epoch 11/100\n",
      "0s - loss: 1.0497 - acc: 0.4272\n",
      "Epoch 12/100\n",
      "0s - loss: 1.0515 - acc: 0.4377\n",
      "Epoch 13/100\n",
      "0s - loss: 1.0497 - acc: 0.4325\n",
      "Epoch 14/100\n",
      "0s - loss: 1.0500 - acc: 0.4272\n",
      "Epoch 15/100\n",
      "0s - loss: 1.0488 - acc: 0.4309\n",
      "Epoch 16/100\n",
      "0s - loss: 1.0471 - acc: 0.4430\n",
      "Epoch 17/100\n",
      "0s - loss: 1.0452 - acc: 0.4294\n",
      "Epoch 18/100\n",
      "0s - loss: 1.0461 - acc: 0.4332\n",
      "Epoch 19/100\n",
      "0s - loss: 1.0456 - acc: 0.4370\n",
      "Epoch 20/100\n",
      "0s - loss: 1.0446 - acc: 0.4355\n",
      "Epoch 21/100\n",
      "0s - loss: 1.0437 - acc: 0.4392\n",
      "Epoch 22/100\n",
      "0s - loss: 1.0441 - acc: 0.4385\n",
      "Epoch 23/100\n",
      "0s - loss: 1.0434 - acc: 0.4325\n",
      "Epoch 24/100\n",
      "0s - loss: 1.0431 - acc: 0.4438\n",
      "Epoch 25/100\n",
      "0s - loss: 1.0422 - acc: 0.4453\n",
      "Epoch 26/100\n",
      "0s - loss: 1.0417 - acc: 0.4408\n",
      "Epoch 27/100\n",
      "0s - loss: 1.0423 - acc: 0.4400\n",
      "Epoch 28/100\n",
      "0s - loss: 1.0423 - acc: 0.4377\n",
      "Epoch 29/100\n",
      "0s - loss: 1.0416 - acc: 0.4460\n",
      "Epoch 30/100\n",
      "0s - loss: 1.0412 - acc: 0.4377\n",
      "Epoch 31/100\n",
      "0s - loss: 1.0402 - acc: 0.4408\n",
      "Epoch 32/100\n",
      "0s - loss: 1.0393 - acc: 0.4460\n",
      "Epoch 33/100\n",
      "0s - loss: 1.0407 - acc: 0.4483\n",
      "Epoch 34/100\n",
      "0s - loss: 1.0400 - acc: 0.4475\n",
      "Epoch 35/100\n",
      "0s - loss: 1.0398 - acc: 0.4438\n",
      "Epoch 36/100\n",
      "0s - loss: 1.0388 - acc: 0.4506\n",
      "Epoch 37/100\n",
      "0s - loss: 1.0388 - acc: 0.4423\n",
      "Epoch 38/100\n",
      "0s - loss: 1.0384 - acc: 0.4483\n",
      "Epoch 39/100\n",
      "0s - loss: 1.0377 - acc: 0.4506\n",
      "Epoch 40/100\n",
      "0s - loss: 1.0370 - acc: 0.4445\n",
      "Epoch 41/100\n",
      "0s - loss: 1.0384 - acc: 0.4558\n",
      "Epoch 42/100\n",
      "0s - loss: 1.0379 - acc: 0.4558\n",
      "Epoch 43/100\n",
      "0s - loss: 1.0373 - acc: 0.4543\n",
      "Epoch 44/100\n",
      "0s - loss: 1.0369 - acc: 0.4453\n",
      "Epoch 45/100\n",
      "0s - loss: 1.0366 - acc: 0.4468\n",
      "Epoch 46/100\n",
      "0s - loss: 1.0363 - acc: 0.4491\n",
      "Epoch 47/100\n",
      "0s - loss: 1.0363 - acc: 0.4468\n",
      "Epoch 48/100\n",
      "0s - loss: 1.0360 - acc: 0.4513\n",
      "Epoch 49/100\n",
      "0s - loss: 1.0355 - acc: 0.4491\n",
      "Epoch 50/100\n",
      "0s - loss: 1.0354 - acc: 0.4551\n",
      "Epoch 51/100\n",
      "0s - loss: 1.0353 - acc: 0.4574\n",
      "Epoch 52/100\n",
      "0s - loss: 1.0352 - acc: 0.4566\n",
      "Epoch 53/100\n",
      "0s - loss: 1.0353 - acc: 0.4491\n",
      "Epoch 54/100\n",
      "0s - loss: 1.0359 - acc: 0.4491\n",
      "Epoch 55/100\n",
      "0s - loss: 1.0349 - acc: 0.4483\n",
      "Epoch 56/100\n",
      "0s - loss: 1.0343 - acc: 0.4574\n",
      "Epoch 57/100\n",
      "0s - loss: 1.0338 - acc: 0.4566\n",
      "Epoch 58/100\n",
      "0s - loss: 1.0340 - acc: 0.4528\n",
      "Epoch 59/100\n",
      "0s - loss: 1.0336 - acc: 0.4589\n",
      "Epoch 60/100\n",
      "0s - loss: 1.0339 - acc: 0.4543\n",
      "Epoch 61/100\n",
      "0s - loss: 1.0335 - acc: 0.4528\n",
      "Epoch 62/100\n",
      "0s - loss: 1.0329 - acc: 0.4581\n",
      "Epoch 63/100\n",
      "0s - loss: 1.0334 - acc: 0.4513\n",
      "Epoch 64/100\n",
      "0s - loss: 1.0326 - acc: 0.4536\n",
      "Epoch 65/100\n",
      "0s - loss: 1.0340 - acc: 0.4589\n",
      "Epoch 66/100\n",
      "0s - loss: 1.0325 - acc: 0.4574\n",
      "Epoch 67/100\n",
      "0s - loss: 1.0323 - acc: 0.4574\n",
      "Epoch 68/100\n",
      "0s - loss: 1.0323 - acc: 0.4574\n",
      "Epoch 69/100\n",
      "0s - loss: 1.0320 - acc: 0.4589\n",
      "Epoch 70/100\n",
      "0s - loss: 1.0322 - acc: 0.4581\n",
      "Epoch 71/100\n",
      "0s - loss: 1.0319 - acc: 0.4528\n",
      "Epoch 72/100\n",
      "0s - loss: 1.0316 - acc: 0.4566\n",
      "Epoch 73/100\n",
      "0s - loss: 1.0320 - acc: 0.4589\n",
      "Epoch 74/100\n",
      "0s - loss: 1.0311 - acc: 0.4649\n",
      "Epoch 75/100\n",
      "0s - loss: 1.0312 - acc: 0.4664\n",
      "Epoch 76/100\n",
      "0s - loss: 1.0308 - acc: 0.4619\n",
      "Epoch 77/100\n",
      "0s - loss: 1.0312 - acc: 0.4551\n",
      "Epoch 78/100\n",
      "0s - loss: 1.0312 - acc: 0.4566\n",
      "Epoch 79/100\n",
      "0s - loss: 1.0309 - acc: 0.4596\n",
      "Epoch 80/100\n",
      "0s - loss: 1.0302 - acc: 0.4604\n",
      "Epoch 81/100\n",
      "0s - loss: 1.0303 - acc: 0.4558\n",
      "Epoch 82/100\n",
      "0s - loss: 1.0307 - acc: 0.4581\n",
      "Epoch 83/100\n",
      "0s - loss: 1.0296 - acc: 0.4596\n",
      "Epoch 84/100\n",
      "0s - loss: 1.0292 - acc: 0.4581\n",
      "Epoch 85/100\n",
      "0s - loss: 1.0304 - acc: 0.4619\n",
      "Epoch 86/100\n",
      "0s - loss: 1.0302 - acc: 0.4611\n",
      "Epoch 87/100\n",
      "0s - loss: 1.0302 - acc: 0.4551\n",
      "Epoch 88/100\n",
      "0s - loss: 1.0294 - acc: 0.4626\n",
      "Epoch 89/100\n",
      "0s - loss: 1.0300 - acc: 0.4574\n",
      "Epoch 90/100\n",
      "0s - loss: 1.0297 - acc: 0.4611\n",
      "Epoch 91/100\n",
      "0s - loss: 1.0302 - acc: 0.4566\n",
      "Epoch 92/100\n",
      "0s - loss: 1.0298 - acc: 0.4543\n",
      "Epoch 93/100\n",
      "0s - loss: 1.0295 - acc: 0.4604\n",
      "Epoch 94/100\n",
      "0s - loss: 1.0292 - acc: 0.4664\n",
      "Epoch 95/100\n",
      "0s - loss: 1.0291 - acc: 0.4642\n",
      "Epoch 96/100\n",
      "0s - loss: 1.0291 - acc: 0.4581\n",
      "Epoch 97/100\n",
      "0s - loss: 1.0290 - acc: 0.4536\n",
      "Epoch 98/100\n",
      "0s - loss: 1.0287 - acc: 0.4604\n",
      "Epoch 99/100\n",
      "0s - loss: 1.0287 - acc: 0.4566\n",
      "Epoch 100/100\n",
      "0s - loss: 1.0285 - acc: 0.4543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b682bb110>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=train_x.shape[1],output_dim=12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, nb_epoch=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.00490403175354, 0.5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45012993,  0.22573498,  0.32413509],\n",
       "       [ 0.61278081,  0.1857394 ,  0.20147982],\n",
       "       [ 0.28402528,  0.27948779,  0.43648693],\n",
       "       [ 0.26227722,  0.31508371,  0.42263907],\n",
       "       [ 0.59369004,  0.19170636,  0.21460359],\n",
       "       [ 0.40284708,  0.26274753,  0.33440539],\n",
       "       [ 0.31861827,  0.27626175,  0.40511999],\n",
       "       [ 0.58384669,  0.18544869,  0.23070464],\n",
       "       [ 0.46458372,  0.20612505,  0.32929125],\n",
       "       [ 0.5014475 ,  0.22525845,  0.27329403]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_liv, \\\n",
    "test_liv, train_edu, test_edu, train_y, test_y = train_test_split(x,liv,edu,y,test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input layer for religion\n",
    "encoder_liv = Sequential()\n",
    "encoder_liv.add(Embedding(liv_cats,4,input_length=1))\n",
    "encoder_liv.add(Flatten())\n",
    "\n",
    "# Input layer for religion\n",
    "encoder_edu = Sequential()\n",
    "encoder_edu.add(Embedding(edu_cats,4,input_length=1))\n",
    "encoder_edu.add(Flatten())\n",
    "\n",
    "# Input layer for triggers(x_b)\n",
    "dense_x = Sequential()\n",
    "dense_x.add(Dense(4, input_dim=x.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([encoder_liv, encoder_edu, dense_x], mode='concat'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dense(output_dim=4))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0s - loss: 1.0894 - acc: 0.3940\n",
      "Epoch 2/100\n",
      "0s - loss: 1.0666 - acc: 0.4098\n",
      "Epoch 3/100\n",
      "0s - loss: 1.0588 - acc: 0.4166\n",
      "Epoch 4/100\n",
      "0s - loss: 1.0524 - acc: 0.4158\n",
      "Epoch 5/100\n",
      "0s - loss: 1.0478 - acc: 0.4196\n",
      "Epoch 6/100\n",
      "0s - loss: 1.0441 - acc: 0.4196\n",
      "Epoch 7/100\n",
      "0s - loss: 1.0397 - acc: 0.4196\n",
      "Epoch 8/100\n",
      "0s - loss: 1.0367 - acc: 0.4234\n",
      "Epoch 9/100\n",
      "0s - loss: 1.0341 - acc: 0.4226\n",
      "Epoch 10/100\n",
      "0s - loss: 1.0314 - acc: 0.4226\n",
      "Epoch 11/100\n",
      "0s - loss: 1.0291 - acc: 0.4249\n",
      "Epoch 12/100\n",
      "0s - loss: 1.0265 - acc: 0.4325\n",
      "Epoch 13/100\n",
      "0s - loss: 1.0250 - acc: 0.4309\n",
      "Epoch 14/100\n",
      "0s - loss: 1.0230 - acc: 0.4362\n",
      "Epoch 15/100\n",
      "0s - loss: 1.0213 - acc: 0.4362\n",
      "Epoch 16/100\n",
      "0s - loss: 1.0196 - acc: 0.4415\n",
      "Epoch 17/100\n",
      "0s - loss: 1.0183 - acc: 0.4392\n",
      "Epoch 18/100\n",
      "0s - loss: 1.0171 - acc: 0.4475\n",
      "Epoch 19/100\n",
      "0s - loss: 1.0156 - acc: 0.4415\n",
      "Epoch 20/100\n",
      "0s - loss: 1.0141 - acc: 0.4506\n",
      "Epoch 21/100\n",
      "0s - loss: 1.0132 - acc: 0.4498\n",
      "Epoch 22/100\n",
      "0s - loss: 1.0121 - acc: 0.4430\n",
      "Epoch 23/100\n",
      "0s - loss: 1.0112 - acc: 0.4498\n",
      "Epoch 24/100\n",
      "0s - loss: 1.0097 - acc: 0.4491\n",
      "Epoch 25/100\n",
      "0s - loss: 1.0091 - acc: 0.4528\n",
      "Epoch 26/100\n",
      "0s - loss: 1.0083 - acc: 0.4536\n",
      "Epoch 27/100\n",
      "0s - loss: 1.0068 - acc: 0.4536\n",
      "Epoch 28/100\n",
      "0s - loss: 1.0062 - acc: 0.4536\n",
      "Epoch 29/100\n",
      "0s - loss: 1.0054 - acc: 0.4551\n",
      "Epoch 30/100\n",
      "0s - loss: 1.0045 - acc: 0.4574\n",
      "Epoch 31/100\n",
      "0s - loss: 1.0037 - acc: 0.4566\n",
      "Epoch 32/100\n",
      "0s - loss: 1.0030 - acc: 0.4589\n",
      "Epoch 33/100\n",
      "0s - loss: 1.0024 - acc: 0.4604\n",
      "Epoch 34/100\n",
      "0s - loss: 1.0016 - acc: 0.4581\n",
      "Epoch 35/100\n",
      "0s - loss: 1.0011 - acc: 0.4626\n",
      "Epoch 36/100\n",
      "0s - loss: 1.0003 - acc: 0.4604\n",
      "Epoch 37/100\n",
      "0s - loss: 0.9997 - acc: 0.4694\n",
      "Epoch 38/100\n",
      "0s - loss: 0.9991 - acc: 0.4664\n",
      "Epoch 39/100\n",
      "0s - loss: 0.9984 - acc: 0.4657\n",
      "Epoch 40/100\n",
      "0s - loss: 0.9980 - acc: 0.4702\n",
      "Epoch 41/100\n",
      "0s - loss: 0.9975 - acc: 0.4709\n",
      "Epoch 42/100\n",
      "0s - loss: 0.9970 - acc: 0.4626\n",
      "Epoch 43/100\n",
      "0s - loss: 0.9963 - acc: 0.4657\n",
      "Epoch 44/100\n",
      "0s - loss: 0.9961 - acc: 0.4679\n",
      "Epoch 45/100\n",
      "0s - loss: 0.9956 - acc: 0.4642\n",
      "Epoch 46/100\n",
      "0s - loss: 0.9949 - acc: 0.4702\n",
      "Epoch 47/100\n",
      "0s - loss: 0.9946 - acc: 0.4702\n",
      "Epoch 48/100\n",
      "0s - loss: 0.9941 - acc: 0.4679\n",
      "Epoch 49/100\n",
      "0s - loss: 0.9937 - acc: 0.4725\n",
      "Epoch 50/100\n",
      "0s - loss: 0.9933 - acc: 0.4732\n",
      "Epoch 51/100\n",
      "0s - loss: 0.9929 - acc: 0.4709\n",
      "Epoch 52/100\n",
      "0s - loss: 0.9924 - acc: 0.4740\n",
      "Epoch 53/100\n",
      "0s - loss: 0.9921 - acc: 0.4732\n",
      "Epoch 54/100\n",
      "0s - loss: 0.9915 - acc: 0.4777\n",
      "Epoch 55/100\n",
      "0s - loss: 0.9911 - acc: 0.4709\n",
      "Epoch 56/100\n",
      "0s - loss: 0.9907 - acc: 0.4777\n",
      "Epoch 57/100\n",
      "0s - loss: 0.9905 - acc: 0.4702\n",
      "Epoch 58/100\n",
      "0s - loss: 0.9902 - acc: 0.4762\n",
      "Epoch 59/100\n",
      "0s - loss: 0.9898 - acc: 0.4785\n",
      "Epoch 60/100\n",
      "0s - loss: 0.9895 - acc: 0.4800\n",
      "Epoch 61/100\n",
      "0s - loss: 0.9891 - acc: 0.4785\n",
      "Epoch 62/100\n",
      "0s - loss: 0.9888 - acc: 0.4808\n",
      "Epoch 63/100\n",
      "0s - loss: 0.9885 - acc: 0.4830\n",
      "Epoch 64/100\n",
      "0s - loss: 0.9882 - acc: 0.4815\n",
      "Epoch 65/100\n",
      "0s - loss: 0.9879 - acc: 0.4762\n",
      "Epoch 66/100\n",
      "0s - loss: 0.9877 - acc: 0.4800\n",
      "Epoch 67/100\n",
      "0s - loss: 0.9873 - acc: 0.4792\n",
      "Epoch 68/100\n",
      "0s - loss: 0.9870 - acc: 0.4830\n",
      "Epoch 69/100\n",
      "0s - loss: 0.9866 - acc: 0.4845\n",
      "Epoch 70/100\n",
      "0s - loss: 0.9864 - acc: 0.4823\n",
      "Epoch 71/100\n",
      "0s - loss: 0.9861 - acc: 0.4860\n",
      "Epoch 72/100\n",
      "0s - loss: 0.9858 - acc: 0.4853\n",
      "Epoch 73/100\n",
      "0s - loss: 0.9857 - acc: 0.4830\n",
      "Epoch 74/100\n",
      "0s - loss: 0.9853 - acc: 0.4883\n",
      "Epoch 75/100\n",
      "0s - loss: 0.9852 - acc: 0.4875\n",
      "Epoch 76/100\n",
      "0s - loss: 0.9849 - acc: 0.4868\n",
      "Epoch 77/100\n",
      "0s - loss: 0.9847 - acc: 0.4830\n",
      "Epoch 78/100\n",
      "0s - loss: 0.9845 - acc: 0.4875\n",
      "Epoch 79/100\n",
      "0s - loss: 0.9841 - acc: 0.4875\n",
      "Epoch 80/100\n",
      "0s - loss: 0.9840 - acc: 0.4883\n",
      "Epoch 81/100\n",
      "0s - loss: 0.9836 - acc: 0.4860\n",
      "Epoch 82/100\n",
      "0s - loss: 0.9834 - acc: 0.4898\n",
      "Epoch 83/100\n",
      "0s - loss: 0.9834 - acc: 0.4860\n",
      "Epoch 84/100\n",
      "0s - loss: 0.9831 - acc: 0.4853\n",
      "Epoch 85/100\n",
      "0s - loss: 0.9828 - acc: 0.4898\n",
      "Epoch 86/100\n",
      "0s - loss: 0.9827 - acc: 0.4913\n",
      "Epoch 87/100\n",
      "0s - loss: 0.9824 - acc: 0.4875\n",
      "Epoch 88/100\n",
      "0s - loss: 0.9822 - acc: 0.4883\n",
      "Epoch 89/100\n",
      "0s - loss: 0.9820 - acc: 0.4989\n",
      "Epoch 90/100\n",
      "0s - loss: 0.9818 - acc: 0.4883\n",
      "Epoch 91/100\n",
      "0s - loss: 0.9816 - acc: 0.4875\n",
      "Epoch 92/100\n",
      "0s - loss: 0.9814 - acc: 0.4958\n",
      "Epoch 93/100\n",
      "0s - loss: 0.9813 - acc: 0.4875\n",
      "Epoch 94/100\n",
      "0s - loss: 0.9811 - acc: 0.4921\n",
      "Epoch 95/100\n",
      "0s - loss: 0.9808 - acc: 0.4989\n",
      "Epoch 96/100\n",
      "0s - loss: 0.9808 - acc: 0.4928\n",
      "Epoch 97/100\n",
      "0s - loss: 0.9804 - acc: 0.4981\n",
      "Epoch 98/100\n",
      "0s - loss: 0.9804 - acc: 0.4981\n",
      "Epoch 99/100\n",
      "0s - loss: 0.9802 - acc: 0.4966\n",
      "Epoch 100/100\n",
      "0s - loss: 0.9799 - acc: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b6fdbf410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_liv[:,None], train_edu[:,None], train_x], train_y, nb_epoch=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.95262736082077026, 0.53378379344940186]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_liv[:,None], test_edu[:,None], test_x],test_y, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48934028,  0.2207204 ,  0.28993931],\n",
       "       [ 0.52064705,  0.21256754,  0.26678541],\n",
       "       [ 0.39323345,  0.23890257,  0.36786398],\n",
       "       [ 0.3042573 ,  0.35569382,  0.34004888],\n",
       "       [ 0.42188928,  0.27930123,  0.2988095 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict([test_liv[:,None], test_edu[:,None], test_x], batch_size=256)\n",
    "p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_10 (Embedding)         (None, 1, 4)          16                                           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)         (None, 1, 4)          16                                           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 4)             20                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 4)             0           merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             5           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1)             0           dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 57\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1325/1325 [==============================] - 0s - loss: 0.6720 - acc: 0.2453     \n",
      "Epoch 2/100\n",
      "1325/1325 [==============================] - 0s - loss: -0.7079 - acc: 0.4264     \n",
      "Epoch 3/100\n",
      "1325/1325 [==============================] - 0s - loss: -1.7836 - acc: 0.4264     \n",
      "Epoch 4/100\n",
      "1325/1325 [==============================] - 0s - loss: -2.7790 - acc: 0.4264     \n",
      "Epoch 5/100\n",
      "1325/1325 [==============================] - 0s - loss: -3.7540 - acc: 0.4264     \n",
      "Epoch 6/100\n",
      "1325/1325 [==============================] - 0s - loss: -4.7403 - acc: 0.4264     \n",
      "Epoch 7/100\n",
      "1325/1325 [==============================] - 0s - loss: -5.7370 - acc: 0.4264     \n",
      "Epoch 8/100\n",
      "1325/1325 [==============================] - 0s - loss: -6.7459 - acc: 0.4264     \n",
      "Epoch 9/100\n",
      "1325/1325 [==============================] - 0s - loss: -7.7802 - acc: 0.4264     \n",
      "Epoch 10/100\n",
      "1325/1325 [==============================] - 0s - loss: -8.8112 - acc: 0.4264     \n",
      "Epoch 11/100\n",
      "1325/1325 [==============================] - 0s - loss: -9.8074 - acc: 0.4264     \n",
      "Epoch 12/100\n",
      "1325/1325 [==============================] - 0s - loss: -10.6871 - acc: 0.4264     \n",
      "Epoch 13/100\n",
      "1325/1325 [==============================] - 0s - loss: -11.3959 - acc: 0.4264     \n",
      "Epoch 14/100\n",
      "1325/1325 [==============================] - 0s - loss: -11.9747 - acc: 0.4264     \n",
      "Epoch 15/100\n",
      "1325/1325 [==============================] - 0s - loss: -12.3898 - acc: 0.4264     \n",
      "Epoch 16/100\n",
      "1325/1325 [==============================] - 0s - loss: -12.7159 - acc: 0.4264     \n",
      "Epoch 17/100\n",
      "1325/1325 [==============================] - 0s - loss: -12.9847 - acc: 0.4264     \n",
      "Epoch 18/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.2036 - acc: 0.4264     \n",
      "Epoch 19/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.3738 - acc: 0.4264     \n",
      "Epoch 20/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.5190 - acc: 0.4264     \n",
      "Epoch 21/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.6323 - acc: 0.4264     \n",
      "Epoch 22/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.7373 - acc: 0.4264     \n",
      "Epoch 23/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.8341 - acc: 0.4264     \n",
      "Epoch 24/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.9037 - acc: 0.4264     \n",
      "Epoch 25/100\n",
      "1325/1325 [==============================] - 0s - loss: -13.9804 - acc: 0.4264     \n",
      "Epoch 26/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.0287 - acc: 0.4264     \n",
      "Epoch 27/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.0927 - acc: 0.4264     \n",
      "Epoch 28/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.1375 - acc: 0.4264     \n",
      "Epoch 29/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.1654 - acc: 0.4264     \n",
      "Epoch 30/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.2105 - acc: 0.4264     \n",
      "Epoch 31/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.2369 - acc: 0.4264     \n",
      "Epoch 32/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.2577 - acc: 0.4264     \n",
      "Epoch 33/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.2804 - acc: 0.4264     \n",
      "Epoch 34/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.3109 - acc: 0.4264     \n",
      "Epoch 35/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.3264 - acc: 0.4264     \n",
      "Epoch 36/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.3419 - acc: 0.4264     \n",
      "Epoch 37/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.3557 - acc: 0.4264     \n",
      "Epoch 38/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.3743 - acc: 0.4264     \n",
      "Epoch 39/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4033 - acc: 0.4264     \n",
      "Epoch 40/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4149 - acc: 0.4264     \n",
      "Epoch 41/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4279 - acc: 0.4264     \n",
      "Epoch 42/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4374 - acc: 0.4264     \n",
      "Epoch 43/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4451 - acc: 0.4264     \n",
      "Epoch 44/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4495 - acc: 0.4264     \n",
      "Epoch 45/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4569 - acc: 0.4264     \n",
      "Epoch 46/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4750 - acc: 0.4264     \n",
      "Epoch 47/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4851 - acc: 0.4264     \n",
      "Epoch 48/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4894 - acc: 0.4264     \n",
      "Epoch 49/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.4937 - acc: 0.4264     \n",
      "Epoch 50/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5023 - acc: 0.4264     \n",
      "Epoch 51/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5043 - acc: 0.4264     \n",
      "Epoch 52/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5065 - acc: 0.4264     \n",
      "Epoch 53/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5098 - acc: 0.4264     \n",
      "Epoch 54/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5131 - acc: 0.4264     \n",
      "Epoch 55/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5146 - acc: 0.4264     \n",
      "Epoch 56/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5166 - acc: 0.4264     \n",
      "Epoch 57/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5209 - acc: 0.4264     \n",
      "Epoch 58/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5372 - acc: 0.4264     \n",
      "Epoch 59/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5405 - acc: 0.4264     \n",
      "Epoch 60/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5456 - acc: 0.4264     \n",
      "Epoch 61/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5461 - acc: 0.4264     \n",
      "Epoch 62/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5479 - acc: 0.4264     \n",
      "Epoch 63/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5489 - acc: 0.4264     \n",
      "Epoch 64/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5499 - acc: 0.4264     \n",
      "Epoch 65/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5527 - acc: 0.4264     \n",
      "Epoch 66/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5552 - acc: 0.4264     \n",
      "Epoch 67/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5565 - acc: 0.4264     \n",
      "Epoch 68/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5570 - acc: 0.4264     \n",
      "Epoch 69/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5576 - acc: 0.4264     \n",
      "Epoch 70/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5584 - acc: 0.4264     \n",
      "Epoch 71/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5593 - acc: 0.4264     \n",
      "Epoch 72/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5604 - acc: 0.4264     \n",
      "Epoch 73/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5610 - acc: 0.4264     \n",
      "Epoch 74/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5623 - acc: 0.4264     \n",
      "Epoch 75/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5626 - acc: 0.4264     \n",
      "Epoch 76/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5632 - acc: 0.4264     \n",
      "Epoch 77/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5636 - acc: 0.4264     \n",
      "Epoch 78/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5647 - acc: 0.4264     \n",
      "Epoch 79/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5676 - acc: 0.4264     \n",
      "Epoch 80/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5686 - acc: 0.4264     \n",
      "Epoch 81/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5744 - acc: 0.4264     \n",
      "Epoch 82/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5766 - acc: 0.4264     \n",
      "Epoch 83/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5771 - acc: 0.4264     \n",
      "Epoch 84/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5787 - acc: 0.4264     \n",
      "Epoch 85/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5788 - acc: 0.4264     \n",
      "Epoch 86/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5790 - acc: 0.4264     \n",
      "Epoch 87/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5793 - acc: 0.4264     \n",
      "Epoch 88/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5797 - acc: 0.4264     \n",
      "Epoch 89/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5806 - acc: 0.4264     \n",
      "Epoch 90/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5814 - acc: 0.4264     \n",
      "Epoch 91/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5816 - acc: 0.4264     \n",
      "Epoch 92/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5817 - acc: 0.4264     \n",
      "Epoch 93/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5834 - acc: 0.4264     \n",
      "Epoch 94/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5848 - acc: 0.4264     \n",
      "Epoch 95/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5852 - acc: 0.4264     \n",
      "Epoch 96/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5859 - acc: 0.4264     \n",
      "Epoch 97/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5866 - acc: 0.4264     \n",
      "Epoch 98/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5868 - acc: 0.4264     \n",
      "Epoch 99/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5870 - acc: 0.4264     \n",
      "Epoch 100/100\n",
      "1325/1325 [==============================] - 0s - loss: -14.5871 - acc: 0.4264     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ee57320>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=x.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
